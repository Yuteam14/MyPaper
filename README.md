# Research Papers

## Content
1. [3D Point Cloud Processing](#3d-point-cloud-processing)
2. [Unsupervised Cross-lingual Alignment](#language-correction)
3. [Few-shot](#few-shot)
4. [Zero-shot](#zero-shot)
5. [Base Model](#Base-model)
6. [Dataset Resources](#dataset-resources)

---
<a id="medical-image-semantic-segmentation"></a>
## 3D Point Cloud Processing

### OOD Detection
1. [2025-ICCV] Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation [[paper]](https://arxiv.org/pdf/2506.22375)  
### Segmentation&&Recognition
1. [2025-CVPR] Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/An_Generalized_Few-shot_3D_Point_Cloud_Segmentation_with_Vision-Language_Model_CVPR_2025_paper.pdf) [[code]](https://github.com/ZhaochongAn/GFS-VL)  
2. [2025-ICLR] MULTIMODALITY HELPS FEW-SHOT 3D POINT CLOUD SEMANTIC SEGMENTATION [[paper]](https://openreview.net/pdf?id=jXvwJ51vcK) [[code]](https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot)  
3. [2025-ICCV] Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds [[paper]](https://arxiv.org/pdf/2508.11265) [[code]](https://github.com/lizhangjie316/Awesome-3D-Point-Cloud-Semantic-Segement)  
4. [2025-CVPR] LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_LogoSP_Local-global_Grouping_of_Superpoints_for_Unsupervised_Semantic_Segmentation_of_CVPR_2025_paper.pdf) [[code]](https://github.com/vLAR-group/LogoSP)
5. [2025-ICCV] UPP: Unified Point-Level Prompting for Robust Point Cloud Analysis [[paper]](https://arxiv.org/pdf/2507.18997) [[code]](https://github.com/zhoujiahuan1991/ICCV2025-UPP)  
6. [2025-ICCV] All in One: Visual-Description-Guided Unified Point Cloud Segmentation [[paper]](https://arxiv.org/pdf/2507.05211) [[code]](https://github.com/Hanzy1996/VDG-Uni3DSeg)  
7. [2025-ICCV] LUDVIG: Learning-Free Uplifting of 2D Visual Features to Gaussian Splatting Scenes [[paper]](https://arxiv.org/pdf/2410.14462) [[code]](https://github.com/naver/ludvig)  
8. [2025-ICCV] WildSeg3D: Segment Any 3D Objects in the Wild from 2D Images [[paper]](https://arxiv.org/pdf/2503.08407)  
9. [2025-arXiv] SegDINO3D: 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features [[paper]](https://arxiv.org/pdf/2509.16098)  
10. [2025-ICCV] SceneSplat: Gaussian Splatting-based Scene Understanding with Vision-Language Pretraining [[paper]](https://arxiv.org/pdf/2503.18052) [[code]](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers)  
11. [2025-arXiv] COS3D: Collaborative Open-Vocabulary 3D Segmentation [[paper]](https://arxiv.org/pdf/2510.20238v1)  
12. [2025-CVPR] Cross-Modal 3D Representation with Multi-View Images and Point Clouds [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Cross-Modal_3D_Representation_with_Multi-View_Images_and_Point_Clouds_CVPR_2025_paper.pdf#:~:text=This%20paper%20introduces%20OpenView%2C%20a%20novel%20representation%20method,multi-view%20images%20to%20form%20a%20unified%203D%20representation.)  
13. [2025-arXiv] Is clustering enough for LiDAR instance segmentation? Astate-of-the-art training-free baseline [[paper]](https://arxiv.org/pdf/2503.13203) [[code]](https://github.com/valeoai/Alpine/)  
14. [2025-NeurIPS] L2RSI: Cross-view LiDAR-based Place Recognition for Large-scale Urban Scenes via Remote Sensing Imagery [[paper]](https://arxiv.org/pdf/2503.11245#page=12.51) [[code]](https://github.com/Shizw695/L2RSI)  
15. [2026-ICLR] Fixinggs: Enhancing 3D Gaussian Splatting Via Training-Free Score Distillation [[paper]](https://openreview.net/attachment?id=QIjmCQuXyx&name=pdf)  
16. [2026-ICLR] Query-Aware Hub Prototype Learning For Few-Shot 3D Point Cloud Segmentation [[paper]](https://openreview.net/attachment?id=AZl4sTVDCC&name=pdf)  
  
### Classification&&Test-time Adaptation
1. [2025-ICCV] Interpretable point cloud classification using multiple instance learning [[paper]](https://openreview.net/pdf?id=T7ZVzuObcj)  
2. [2025-ICCV] Purge-Gate: Backpropagation-Free Test-Time Adaptation For Point Clouds Classification Via Token [[paper]](https://arxiv.org/pdf/2509.09785v1)
3. [2025-ICML] SMART-PC: Skeletal Model Adaptation for Robust Test-Time Training in Point Clouds [[paper]](https://arxiv.org/pdf/2505.19546) [[code]](https://github.com/AliBahri94/SMART-PC)  
4. [2025-CVPR] Point-Cache: Test-time Dynamic and Hierarchical Cache for Robust and Generalizable Point Cloud Analysis [[paper]](https://arxiv.org/pdf/2503.12150) [[code]](https://github.com/auniquesun/Point-Cache)  
5. [2025-CVPR] Purge-Gate: Efficient Backpropagation-Free Test-Time Adaptation for Point Clouds via Token Purging [[paper]](https://iccv.thecvf.com/virtual/2025/poster/1863) [[code]](https://github.com/MosyMosy/Purge-Gate)  
### Information Retrieval
1. [2025-ICCV] Describe, Adapt and Combine: Empowering CLIP Encoders for Open-set 3D Object Retrieval [[paper]](https://arxiv.org/pdf/2507.21489) [[code]](https://github.com/wangzhichuan123/DAC)  
### Localization
1. [2025-ICCV] Partially Matching Submap Helps: Uncertainty Modeling and Propagation for Text to Point Cloud Localization [[code]](https://github.com/Afoolbird/PMSH)  
### 3D Reconstruction
1. [2025-arXiv] MapAnything: Universal Feed-Forward Metric 3D Reconstruction [[paper]](https://map-anything.github.io/assets/MapAnything.pdf) [[code]](https://github.com/facebookresearch/map-anything)  
2. [2025-arXiv] Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey [[paper]](https://arxiv.org/pdf/2507.14501)  
3. [2025-arXiv] IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction [[paper]](https://arxiv.org/pdf/2510.22706)  
4. [2025-arXiv] Gaussian Herding across Pens: An Optimal Transport Perspective on Global Gaussian Reduction for 3DGS [[paper]](https://arxiv.org/pdf/2510.22706) [[code]](https://github.com/DrunkenPoet/GHAP)  
### 3D Alignment
1. [2025-arXiv] Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces [[paper]](https://arxiv.org/pdf/2503.05283)  
2. [2025-arXiv] Robust Cross-modal Alignment Learning for Cross-Scene Spatial Reasoning and Grounding [[paper]](https://arxiv.org/pdf/2506.09534)  
3. [2025-NeurIPS] SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions [[paper]](https://arxiv.org/pdf/2509.15693) [[code]](https://github.com/mortorit/sceneforge-neurips2025)  
--- 
<a id="language-correction"></a>
## Unsupervised Cross-lingual Alignment

1. [2018-EMNLP] Loss in Translation: Learning Bilingual Word Mapping with a Retrieval Criterion [[paper]](https://arxiv.org/pdf/1804.07745)  
2. [2018-arXiv] Unsupervised Alignment of Embeddings with Wasserstein Procrustes [[paper]](https://arxiv.org/pdf/1805.11222)  
3. [2018-TACL] Learning Multilingual Word Embeddings in Latent Metric Space: A Geometric Approach [[paper]](https://arxiv.org/pdf/1808.08773)  
4. [2019-NAACL] Density Matching for Bilingual Word Embedding [[paper]](https://arxiv.org/pdf/1904.02343) [[code]](https://github.com/violet-zct/DeMa-BWE)  
5. [2019-ACL] Bilingual Lexicon Induction with Semi-supervision in Non-Isometric Embedding Spaces [[paper]](https://arxiv.org/pdf/1908.06625)  
6. [2020-arXiv] A Call for More Rigor in Unsupervised Cross-lingual Learning [[paper]](https://arxiv.org/pdf/2004.14958)  
7. [2023-ACL] Unbalanced Optimal Transport for Unbalanced Word Alignment [[paper]](https://aclanthology.org/2023.acl-long.219.pdf)  
8. [2023-ICCV] Black Box Few-Shot Adaptation for Vision-Language models [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf#page=4.97)[[code]](https://github.com/saic-fi/LFA) [[note]](https://yuteam14.github.io/MyPaper/Note/LFA%E6%96%B9%E6%B3%95.pdf)  
9. [2025-ACL] Non-linear instance-based cross-lingual mapping for non-isomorphic embedding spaces [[paper]](https://aclanthology.org/2020.acl-main.675.pdf) [[code]](https://aclanthology.org/2020.acl-main.675.pdf)  
10. [2025-arXiv] Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment [[paper]](https://arxiv.org/pdf/2508.15568)  
11. [2025-arXiv] Exploring Cross-Modal Flows For Few-Shot Learning [[paper]](https://arxiv.org/pdf/2510.14543)  
12. [2025-arXiv] Enhancing CLIP Robustness via Cross-Modality Alignment [[paper]](https://arxiv.org/pdf/2510.24038)  
13. [2025-ICCV] Gaze-Language Alignment for Zero-Shot Prediction of Visual Search Targets from Human Gaze Scanpaths [[paper]](https://openaccess.thecvf.com/content/ICCV2025/papers/Mondal_Gaze-Language_Alignment_for_Zero-Shot_Prediction_of_Visual_Search_Targets_from_ICCV_2025_paper.pdf)  
14. [2025-ICCV] On a Novel Application of Wasserstein-Procrustes for Unsupervised Cross-Lingual Alignment of Embeddings [[paper]](https://aclanthology.org/2024.bucc-1.1.pdf)  
15. [2025-ICLR] UNSUPERVISED HYPERALIGNMENT FOR MULTILIN GUAL WORD EMBEDDINGS [[paper]](https://arxiv.org/pdf/1811.01124)  
16. [2025-ICML] Towards an Explainable Comparison and Alignment of Feature Embeddings [[paper]](https://arxiv.org/pdf/2506.06231) [[code]](https://github.com/mjalali/embedding-comparison)  
17. [2025-NeurIPS] VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set [[paper]](https://arxiv.org/pdf/2510.21323) [[code]](https://github.com/ssfgunner/VL-SAE)  
18. [2026-ICLR] Flow-Based Alignment Of Uni-Modal Vision And Text Encoders For Few-Shot Image Classification [[paper]](https://openreview.net/attachment?id=educGk5ykl&name=pdf)  
19. [2026-ICLR] Transport Clustering: Solving Low-Rank Optimal Transport Via Clustering [[paper]](https://openreview.net/attachment?id=YKTJJCNXF4&name=pdf)  

---

<a id="few-shot"></a>
## Few-shot
1. [2026-ICLR] Muot-Clip: Enhancing Few-Shot Adaptation Of Clip Via Inter- And Intra-Modality Unbalanced Optimal Transport [[paper]](https://openreview.net/attachment?id=BEOq3YB5WM&name=pdf)  
2. [2026-ICLR] Graph-Refined Representation Learning For Few-Shot Classification Via Clip Adaptation [[paper]](https://openreview.net/pdf?id=KQ9aK65BKm)   
3. [2026-ICLR] Infer: Embedding Integration With Feature Refinement For Few-Shot Learning In Vlms [[paper]](https://openreview.net/attachment?id=sD18KHrPbB&name=pdf)   
4. [2026-ICLR] Semobridge: Semantic Modality Bridge For Efficient Few-Shot Adaptation Of Clip [[paper]](https://openreview.net/attachment?id=8aT5yt8Vmt&name=pdf)   
5. [2025-CVPR] ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models [[paper]](https://arxiv.org/pdf/2501.11175)[[code]](https://github.com/ybendou/ProKeR)  
6. [2025-AAAI] Text and Image Are Mutually Beneficial: Enhancing Training-Free Few-Shot Classification with CLIP [[paper]](https://arxiv.org/pdf/2412.11375)[[code]](https://github.com/MCPathology/NH2ST)  
7. [2025-ICCV] Unknown Text Learning for CLIP-based Few-shot Open-Set Recognition [[paper]](https://openaccess.thecvf.com/content/ICCV2025/papers/Ma_Unknown_Text_Learning_for_CLIP-based_Few-Shot_Open-set_Recognition_ICCV_2025_paper.pdf)  
8. [2025-CVPR] Rethinking Few-Shot Adaptation of Vision-Language Models in Two Stages [[paper]](https://arxiv.org/pdf/2503.11609)[[code]](https://github.com/FarinaMatteo/rethinking_fewshot_vlms)  
---
<a id="zero-shot"></a>
## Zero-shot
1. [2025-arXiv] Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignmen [[paper]](https://arxiv.org/pdf/2508.15568)  
2. [2024-NeurIPS] Enhancing Zero-Shot Vision Models by Label-Free Prompt Distribution Learning and Bias Correcting [[paper]](https://proceedings.neurips.cc/paper_files/paper/2024/file/03cdf8e212ba92a3f36bffe1391928bd-Paper-Conference.pdf)  
3. [2025-CVPR] OnlineAnySeg: Online Zero-Shot 3D Segmentation by Visual Foundation Model Guided 2D Mask Merging [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_OnlineAnySeg_Online_Zero-Shot_3D_Segmentation_by_Visual_Foundation_Model_Guided_CVPR_2025_paper.pdf)  
4. [2025-CVPR] Compositional Caching for Training-free Open-vocabulary Attribute Detection [[paper]](https://arxiv.org/pdf/2503.19145)  
5. [2025-ICCV] Think Twice: Test-Time Reasoning for Robust CLIP Zero-Shot Classification [[paper]](https://openaccess.thecvf.com/content/ICCV2025/papers/Lu_Think_Twice_Test-Time_Reasoning_for_Robust_CLIP_Zero-Shot_Classification_ICCV_2025_paper.pdf)   



---
<a id="clip"></a>
## Base Model

1. [2025-CVPR] COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation [[paper]](https://arxiv.org/pdf/2503.23388) [[code]](待补充)   
2. [2025-ICLR] EFFICIENT AND CONTEXT-AWARE LABEL PROPAGA TION FOR ZERO-/FEW-SHOT TRAINING-FREE ADAP TATION OF VISION-LANGUAGE MODEL [[paper]](https://arxiv.org/pdf/2412.18303) [[code]](https://github.com/Yushu-Li/ECALP) [[note]](https://yuteam14.github.io/MyPaper/Note/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3.pdf)      
3. [2024-arXiv] Boosting Vision-Language Models with Transduction [[paper]](https://arxiv.org/pdf/2406.01837) [[code]](https://github.com/MaxZanella/transduction-for-vlms)  
4. [2025-arXiv] ViLU: Learning Vision-Language Uncertainties for Failure Prediction [[paper]](https://arxiv.org/pdf/2507.07620)[[code]](https://github.com/ykrmm/ViLU)  
5. [2025-arXiv] SGPMIL: Sparse Gaussian Process Multiple Instance Learning [[paper]](https://arxiv.org/pdf/2507.08711)   
6. [2025-arXiv] Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model [[paper]](https://arxiv.org/pdf/2506.23822)  
7. [2023-ICCV] Black Box Few-Shot Adaptation for Vision-Language models [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf#page=4.97)[[code]](https://github.com/saic-fi/LFA) [[note]](https://yuteam14.github.io/MyPaper/Note/LFA%E6%96%B9%E6%B3%95.pdf)  
8. [2025-CVPR] ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models [[paper]](https://arxiv.org/pdf/2501.11175)[[code]](https://github.com/ybendou/ProKeR)  
9. [2025-AAAI] Text and Image Are Mutually Beneficial: Enhancing Training-Free Few-Shot Classification with CLIP [[paper]](https://arxiv.org/pdf/2412.11375)[[code]](https://github.com/MCPathology/NH2ST)  
10. [2025-CVPR] ViLU: Learning Vision-Language Uncertainties for Failure Prediction [[paper]](https://arxiv.org/pdf/2507.07620?)[[code]](https://github.com/ykrmm/ViLU)  
11. [2025-arXiv] Recent Advances in Optimal Transport for Machine Learning [[paper]](https://arxiv.org/pdf/2306.16156)  
12. [2026-ICLR] A Novel Graph-Based Fuzzy Clustering For Deep Visual Representations [[paper]](https://openreview.net/attachment?id=AorEBT2QLl&name=pdf)  
13. [2026-ICLR] Uncover Underlying Correspondence For Robust Multi-View Clustering [[paper]](https://openreview.net/attachment?id=a4S1nQay3b&name=pdf)  
14. [2026-ICLR] Reorienting The Frozen Space: Training-Free Test-Time Adaptation By Geometric Transformation [[paper]](https://openreview.net/attachment?id=nErnNhJx2o&name=pdf)  
15. [2025-CVPR] MMRL:Multi-Modal Representation Learning for Vision-Language Models [[paper]](https://arxiv.org/pdf/2503.08497)  
---

<a id="dataset-resources"></a>
## Dataset Resources


- **通用视觉**  
  - [COCO](https://cocodataset.org) (开放词汇分割基准)
