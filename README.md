# Research Papers

## Content
1. [Medical Image Semantic Segmentation](#medical-image-semantic-segmentation)
2. [Classic Model](#classic-model)
3. [Benchmark](#Benchmark)
4. [Dataset Resources](#dataset-resources)

---

<a id="medical-image-semantic-segmentation"></a>
## Medical Image Semantic Segmentation

1. [2025 MICCAI] Conservative-Radical Complementary Learning for Class-incremental Medical Image Analysis with Pre-trained Foundation Models [[paper]](https://arxiv.org/pdf/2407.13768)  
2. [2025 MICCAI] D-CAM: Learning Generalizable Weakly-Supervised Medical Image Segmentation from Domain-invariant CAM [[paper]](待补充) [[code]](https://github.com/JingjunYi/D-CAM)  
3. [2025 MICCAI] Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations [[paper]](https://arxiv.org/pdf/2506.17136)   
4. [2025 CVPR] Prototype-Based Image Prompting for Weakly Supervised Histopathological Image Segmentation [[paper]](https://arxiv.org/pdf/2503.12068)[[code]](https://github.com/QingchenTang/PBIP?tab=readme-ov-file)  
5. [2025 CVPR] Multi-modal Topology-embedded Graph Learning for Spatially Resolved Genes Prediction from Pathology Images with Prior Gene Similarity Information [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_Multi-modal_Topology-embedded_Graph_Learning_for_Spatially_Resolved_Genes_Prediction_from_CVPR_2025_paper.pdf)[[code]](https://github.com/MedAIerHHL/CVPR-MIA)  
6. [2025 ICLR] VLSA: Interpretable Vision-Language Survival Analysis with Ordinal Inductive Bias for Computational Pathology [[paper]](https://openreview.net/pdf?id=trj2Jq8riA)[[code]](https://github.com/liupei101/VLSA?tab=readme-ov-file#-awesome-papers-of-pathology-vlms) [[note]](https://yuteam14.github.io/MyPaper/Note/%E7%97%85%E7%90%86%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB.pdf)  
7. [2025 CV] Tile-level Histopathology image Understanding benchmark [[paper]](https://arxiv.org/pdf/2507.07860)[[code]](https://github.com/MICS-Lab/thunder)    
8. [2025 Nature] A vision–language foundation model for precision oncology [[code]](https://github.com/lilab-stanford/MUSK)   
9. [2025 arXiv] Test-time Adaptation for Foundation Medical Segmentation Model Without Parametric Updates [[paper]](https://arxiv.org/pdf/2504.02008)[[code]](https://github.com/ecoxial2007/Expert-CFG)   
10. [2025 arXiv] ModalTune: Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information for Multi-task Learning in Digital Pathology [[paper]](https://arxiv.org/pdf/2503.17564)  
11. [2025 arXiv] Segment Anything in Pathology Images with Natural Language [[paper]](https://arxiv.org/pdf/2506.20988)  
12. [2025 arXiv] Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation [[paper]](https://arxiv.org/pdf/2507.11055)
13. [2024 NeurIPS] FAST: A Dual-tier Few-Shot Learning Paradigm for Whole Slide Image Classification [[paper]](https://proceedings.neurips.cc/paper_files/paper/2024/file/bdcdf38389d7fcefc73c4c3720217155-Paper-Conference.pdf)[[code]](https://github.com/fukexue/FAST)  
14. [2025 MICCAI] Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction [[paper]](https://arxiv.org/pdf/2506.17503)[[code]](https://github.com/jusiro/SCA-T)  
15. [2025 MICCAI] Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning [[paper]](https://arxiv.org/pdf/2506.23827)  
16. [2024 ICCV] CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment [[paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Javed_CPLIP_Zero-Shot_Learning_for_Histopathology_with_Comprehensive_Vision-Language_Alignment_CVPR_2024_paper.pdf)[[code]](https://github.com/iyyakuttiiyappan/CPLIP)  
17. [2025 ICCV] AcZeroTS: Active Learning for Zero-shot Tissue Segmentation in Pathology Images  
18. [2025 ICCV] ModalTune: Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information for Multi-task Learning in Digital Pathology [[paper]](https://arxiv.org/pdf/2503.17564)  
19. [2025 ICCV] COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation [[paper]](https://arxiv.org/pdf/2503.11439)[[code]](https://github.com/shjo-april/COIN)  
---

<a id="clip"></a>
## classic Model

1. [2025 CVPR] COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation [[paper]](https://arxiv.org/pdf/2503.23388) [[code]](待补充)  
2. [2025-ICLR] EFFICIENT AND CONTEXT-AWARE LABEL PROPAGA TION FOR ZERO-/FEW-SHOT TRAINING-FREE ADAP TATION OF VISION-LANGUAGE MODEL [[paper]](https://arxiv.org/pdf/2412.18303) [[code]](https://github.com/Yushu-Li/ECALP) [[note]](https://yuteam14.github.io/MyPaper/Note/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3.pdf)      
3. [2024-arXiv] Boosting Vision-Language Models with Transduction [[paper]](https://arxiv.org/pdf/2406.01837) [[code]](https://github.com/MaxZanella/transduction-for-vlms)  
4. [2025 arXiv] ViLU: Learning Vision-Language Uncertainties for Failure Prediction [[paper]](https://arxiv.org/pdf/2507.07620)[[code]](https://github.com/ykrmm/ViLU)  
5. [2025 arXiv] SGPMIL: Sparse Gaussian Process Multiple Instance Learning [[paper]](https://arxiv.org/pdf/2507.08711)  
6. [2025 arXiv] Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model [[paper]](https://arxiv.org/pdf/2506.23822)  
7. [2023 ICCV] Black Box Few-Shot Adaptation for Vision-Language models [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf#page=4.97)[[code]](https://github.com/saic-fi/LFA) [[note]](https://yuteam14.github.io/MyPaper/Note/LFA%E6%96%B9%E6%B3%95.pdf)  
8. [2025 CVPR] ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models [[paper]](https://arxiv.org/pdf/2501.11175)[[code]](https://github.com/ybendou/ProKeR)
9. [2025 AAAI] Text and Image Are Mutually Beneficial: Enhancing Training-Free Few-Shot Classification with CLIP [[paper]](https://arxiv.org/pdf/2412.11375)[[code]](https://github.com/MCPathology/NH2ST)  

<a id="clip"></a>
## Benchmark


<a id="dataset-resources"></a>
## Dataset Resources

- **医学影像**  
  - [Medical Segmentation Decathlon](http://medicaldecathlon.com/) (多器官分割)  
  - [BraTS](https://www.med.upenn.edu/cbica/brats/) (脑肿瘤分割)  

- **通用视觉**  
  - [COCO](https://cocodataset.org) (开放词汇分割基准)
